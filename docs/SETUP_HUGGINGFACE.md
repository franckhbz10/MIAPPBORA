# ü§ñ Configuraci√≥n de HuggingFace para MIAPPBORA

## Paso 1: Crear Cuenta en HuggingFace

1. Ve a https://huggingface.co
2. Haz clic en **Sign Up** (esquina superior derecha)
3. Reg√≠strate con email o GitHub
4. Verifica tu email

## Paso 2: Obtener Token de API

1. Una vez logueado, ve a tu perfil (esquina superior derecha)
2. Click en **Settings** ‚Üí **Access Tokens**
3. O ve directamente a: https://huggingface.co/settings/tokens
4. Haz clic en **New token**
5. Configuraci√≥n del token:
   - **Name**: `miappbora`
   - **Role**: `read` (solo lectura es suficiente)
6. Copia el token (empieza con `hf_...`)

‚ö†Ô∏è **IMPORTANTE**: Guarda el token inmediatamente, solo se muestra una vez

## Paso 3: Configurar Token en .env

Abre el archivo `backend/.env` y actualiza:

```env
HUGGINGFACE_API_KEY=hf_tu_token_real_aqui
```

## Paso 4: Instalar Dependencias

```bash
cd backend
pip install sentence-transformers transformers torch
```

**Nota sobre torch**: La descarga puede ser grande (~2GB), ten paciencia.

### Instalaci√≥n alternativa (m√°s ligera):

Si tienes problemas con torch, usa la versi√≥n CPU:
```bash
pip install sentence-transformers transformers torch --index-url https://download.pytorch.org/whl/cpu
```

## Paso 5: Verificar Instalaci√≥n

```bash
python -c "from sentence_transformers import SentenceTransformer; print('‚úÖ OK')"
```

## Paso 6: Generar Embeddings del Corpus

Una vez instaladas las dependencias, ejecuta:

```bash
python scripts/generate_embeddings.py
```

Este script:
- ‚úÖ Carga el modelo `sentence-transformers/all-MiniLM-L6-v2`
- ‚úÖ Genera vectores de 384 dimensiones para cada frase
- ‚úÖ Guarda los embeddings en Supabase (tabla `phrase_embeddings`)
- ‚úÖ Habilita b√∫squeda sem√°ntica para el chat RAG

---

## üìä Modelos Utilizados

### Embedding Model
- **Modelo**: `sentence-transformers/all-MiniLM-L6-v2`
- **Dimensi√≥n**: 384
- **Tama√±o**: ~80MB
- **Uso**: Convertir texto a vectores para b√∫squeda sem√°ntica
- **Idioma**: Multiling√ºe (funciona con Bora y Espa√±ol)

### LLM Model (Chat)
- **Modelo**: `microsoft/DialoGPT-medium`
- **Tama√±o**: ~350MB
- **Uso**: Generar respuestas conversacionales
- **Nota**: Puedes cambiarlo por otros modelos seg√∫n necesidad

---

## üîß Troubleshooting

### Error: "No module named 'torch'"
```bash
pip install torch --index-url https://download.pytorch.org/whl/cpu
```

### Error: "Slow download speeds"
- HuggingFace descarga modelos la primera vez
- Los modelos se cachean localmente en `~/.cache/huggingface`
- Siguientes ejecuciones ser√°n mucho m√°s r√°pidas

### Error: "CUDA not available"
- Es normal si no tienes GPU NVIDIA
- Los modelos funcionar√°n en CPU (m√°s lento pero funcional)
- Para esta app, CPU es suficiente

### Error: "Out of memory"
- Los modelos elegidos son ligeros (~500MB total)
- Si tienes problemas, cierra otras aplicaciones
- M√≠nimo recomendado: 4GB RAM

---

## ‚úÖ Checklist

- [ ] Cuenta en HuggingFace creada
- [ ] Token de API generado
- [ ] Token agregado a `.env`
- [ ] `sentence-transformers` instalado
- [ ] `transformers` instalado
- [ ] `torch` instalado
- [ ] Test de importaci√≥n exitoso
- [ ] Embeddings generados

---

## üéØ Siguiente Paso

Una vez que tengas los embeddings generados, podr√°s:

1. **Probar el chat RAG** - Preguntar en espa√±ol y recibir frases Bora relevantes
2. **B√∫squeda sem√°ntica** - Encontrar frases por significado, no solo palabras exactas
3. **Minijuegos inteligentes** - Generar quizzes personalizados

**Tiempo estimado total**: 15-20 minutos (dependiendo de velocidad de descarga)
