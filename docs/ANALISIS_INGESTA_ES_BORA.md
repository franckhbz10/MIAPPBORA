# ðŸ“Š AnÃ¡lisis: Ingesta de Diccionario EspaÃ±olâ†’Bora

## ðŸŽ¯ Objetivo
DiseÃ±ar estrategia Ã³ptima para ingestar `salida_es_bora_final.json` (diccionario ESâ†’Bora) complementando el existente `salida.json` (Boraâ†’ES).

---

## ðŸ“ ComparaciÃ³n de Estructuras JSON

### **salida.json** (Boraâ†’ES) - ACTUAL
```json
{
  "lemma": "aÃ¡bukÉ¨",           // Palabra en BORA
  "gloss_es": "sol",            // TraducciÃ³n al espaÃ±ol
  "pos": "s",
  "pos_full": "sustantivo",
  "page": 1,
  "variants": ["aÃ¡bukÉ¨É¨"],
  "examples": [
    {
      "bora": "AÃ¡bukÉ¨ tsaallÃ©",
      "es": "El sol brilla"
    }
  ],
  "subentries": [
    {
      "sublemma": "aÃ¡bukÉ¨ tsÃºÃºhne",
      "gloss_es": "mediodÃ­a",
      "examples": [...]
    }
  ]
}
```

### **salida_es_bora_final.json** (ESâ†’Bora) - NUEVO
```json
{
  "lemma": "a",                 // Palabra en ESPAÃ‘OL
  "gloss_bora": "ri; vu",       // TraducciÃ³n(es) al Bora
  "pos": "prep.",
  "pos_full": "preposiciÃ³n",
  "variants": [],
  "synonyms": [],
  "subentries": [
    {
      "lemma": "a cambio",      // Frase en ESPAÃ‘OL
      "gloss_bora": "hallÃºvu",  // TraducciÃ³n al Bora
      "pos": "prep.",
      "examples": [
        {
          "es": "RecibÃ­ dos ollas a cambio de mi gallina.",
          "bora": "TÃ¡cÃ¡racÃ¡ hallÃºvÃº Ã³ ujcÃº llÃ­yihllÃ³cu."
        }
      ]
    }
  ]
}
```

---

## ðŸ” Diferencias Clave

| Aspecto | salida.json (Boraâ†’ES) | salida_es_bora_final.json (ESâ†’Bora) |
|---------|----------------------|-------------------------------------|
| **Lemma** | Palabra en Bora | Palabra en EspaÃ±ol |
| **Gloss** | `gloss_es` (1 traducciÃ³n) | `gloss_bora` (mÃºltiples: "ri; vu") |
| **DirecciÃ³n** | Bora â†’ EspaÃ±ol | EspaÃ±ol â†’ Bora |
| **MÃºltiples traducciones** | No | SÃ­ (separadas por ";") |
| **SinÃ³nimos** | No usado | Campo presente (vacÃ­o) |
| **Subentries** | Frases derivadas en Bora | Frases compuestas en EspaÃ±ol |

---

## âš ï¸ DesafÃ­os Identificados

### 1. **MÃºltiples Traducciones en `gloss_bora`**
```json
"gloss_bora": "ri; vu"  // Â¿CÃ³mo vectorizar esto?
```

**Opciones**:
- âœ… **A) Crear un documento por traducciÃ³n**
  ```
  "[LEMMA_ES] a | DEF_BORA: ri | POS: preposiciÃ³n"
  "[LEMMA_ES] a | DEF_BORA: vu | POS: preposiciÃ³n"
  ```
  
- âŒ **B) Concatenar todas**
  ```
  "[LEMMA_ES] a | DEF_BORA: ri; vu | POS: preposiciÃ³n"
  ```
  **Problema**: VectorizaciÃ³n menos precisa

**RecomendaciÃ³n**: **OpciÃ³n A** - Split por ";" y generar documentos separados

---

### 2. **Esquema de Base de Datos**

#### OpciÃ³n 1: **Reusar tablas existentes** (âš ï¸ ProblemÃ¡tico)
```sql
-- lexicon_lemmas
lemma: "a"          -- Â¿EspaÃ±ol o Bora?
gloss_es: NULL      -- No aplica para ESâ†’Bora
gloss_bora: "ri"    -- âŒ Campo no existe
```

**Problemas**:
- `gloss_es` es NOT NULL en schema actual
- ConfusiÃ³n: Â¿el lemma es ES o Bora?
- Mixing de direcciones en misma tabla

#### OpciÃ³n 2: **Tablas espejo para ESâ†’Bora** (âœ… Limpio)
```sql
-- Nuevas tablas:
CREATE TABLE lexicon_lemmas_es_bora (
  id BIGSERIAL PRIMARY KEY,
  lemma TEXT NOT NULL,          -- Palabra en espaÃ±ol
  gloss_bora TEXT NOT NULL,     -- TraducciÃ³n(es) al Bora
  pos TEXT,
  pos_full TEXT,
  variants TEXT[],
  synonyms TEXT[],
  source TEXT DEFAULT 'salida_es_bora_final.json',
  created_at TIMESTAMPTZ DEFAULT NOW()
);

CREATE TABLE lexicon_subentries_es_bora (...);
CREATE TABLE lexicon_examples_es_bora (...);
```

**Ventajas**:
- âœ… SeparaciÃ³n clara de direcciones
- âœ… Schema especÃ­fico para cada diccionario
- âœ… Queries no confusas

**Desventajas**:
- âŒ DuplicaciÃ³n de estructura
- âŒ MÃ¡s tablas para mantener

#### OpciÃ³n 3: **Columnas adicionales en tablas existentes** (âœ… Flexible)
```sql
-- Modificar tablas existentes:
ALTER TABLE lexicon_lemmas
  ADD COLUMN direction TEXT DEFAULT 'bora_es',  -- 'bora_es' | 'es_bora'
  ADD COLUMN gloss_bora TEXT,                   -- Para ESâ†’Bora
  ALTER COLUMN gloss_es DROP NOT NULL;          -- Permitir NULL

-- Constraint: al menos uno de los dos debe existir
ALTER TABLE lexicon_lemmas
  ADD CONSTRAINT check_has_gloss 
  CHECK (gloss_es IS NOT NULL OR gloss_bora IS NOT NULL);
```

**Ventajas**:
- âœ… Una sola tabla para ambas direcciones
- âœ… FÃ¡cil filtrar por `direction`
- âœ… ReutilizaciÃ³n de infraestructura

---

### 3. **Formato de Documentos para `bora_docs`**

#### Documentos tipo LEMMA (ESâ†’Bora)
```python
# ANTES (Boraâ†’ES):
"[LEMMA] aÃ¡bukÉ¨ | DEF_ES: sol | POS: sustantivo | PAG: 1"

# NUEVO (ESâ†’Bora):
"[LEMMA_ES] a | DEF_BORA: ri | POS: preposiciÃ³n | PAG: 15"
"[LEMMA_ES] a | DEF_BORA: vu | POS: preposiciÃ³n | PAG: 15"  # Si hay mÃºltiples
```

#### Documentos tipo SUBENTRY
```python
# ANTES (Boraâ†’ES):
"[SUBLEMMA] aÃ¡bukÉ¨ tsÃºÃºhne | DEF_ES: mediodÃ­a | POS: locuciÃ³n"

# NUEVO (ESâ†’Bora):
"[SUBLEMMA_ES] a cambio | DEF_BORA: hallÃºvu | POS: preposiciÃ³n"
```

#### Documentos tipo EXAMPLE (mantener formato)
```python
# Mismo formato para ambas direcciones:
"BORA: TÃ¡cÃ¡racÃ¡ hallÃºvÃº Ã³ ujcÃº llÃ­yihllÃ³cu. [SEP] ES: RecibÃ­ dos ollas a cambio de mi gallina. [SEP] LEMMA: a cambio POS: preposiciÃ³n"
```

---

## ðŸ“Š EstadÃ­sticas Estimadas

### salida.json (Boraâ†’ES)
```
Entradas: ~2,450
Lemmas: ~2,180
Subentries: ~450
Examples: ~3,200
Documentos vectorizados: ~5,830
```

### salida_es_bora_final.json (ESâ†’Bora)
```json
// Archivo: 101,060 lÃ­neas
// AnÃ¡lisis necesario:
- Contar entradas Ãºnicas
- Contar subentries
- Contar examples
- Estimar documentos finales
```

**EstimaciÃ³n conservadora** (basada en ratio):
```
Entradas: ~8,000-12,000 (mÃ¡s palabras en ES que en Bora)
Subentries: ~2,000-3,000
Examples: ~10,000-15,000
Documentos vectorizados: ~20,000-30,000

Embeddings a generar: ~25,000 vectores (1536 dims)
Llamadas a OpenAI: ~400 batches (64 cada uno)
Costo estimado: ~$0.50-1.00 USD
Tiempo estimado: ~15-20 minutos
```

---

## ðŸš€ Estrategia Recomendada

### **OpciÃ³n Preferida: Esquema Bidireccional Unificado**

#### 1. **Modificar Schema SQL**
```sql
-- Agregar columnas para ambas direcciones
ALTER TABLE lexicon_lemmas
  ADD COLUMN direction TEXT DEFAULT 'bora_es' CHECK (direction IN ('bora_es', 'es_bora')),
  ADD COLUMN gloss_bora TEXT,
  ALTER COLUMN gloss_es DROP NOT NULL,
  ADD CONSTRAINT check_has_gloss CHECK (gloss_es IS NOT NULL OR gloss_bora IS NOT NULL);

ALTER TABLE lexicon_subentries
  ADD COLUMN direction TEXT DEFAULT 'bora_es' CHECK (direction IN ('bora_es', 'es_bora')),
  ADD COLUMN gloss_bora TEXT,
  ALTER COLUMN gloss_es DROP NOT NULL,
  ADD CONSTRAINT check_has_gloss CHECK (gloss_es IS NOT NULL OR gloss_bora IS NOT NULL);

-- Ãndices para bÃºsqueda por direcciÃ³n
CREATE INDEX idx_lemmas_direction ON lexicon_lemmas(direction);
CREATE INDEX idx_subentries_direction ON lexicon_subentries(direction);
```

#### 2. **Script de Ingesta: `ingest_es_bora_docs.py`**

```python
def build_lemmas_es_bora(data: List[Dict]) -> List[Dict]:
    """
    Construye lemmas desde salida_es_bora_final.json
    
    DIFERENCIA CLAVE: Split de gloss_bora si tiene mÃºltiples traducciones
    """
    out = []
    seen = set()
    
    for e in data:
        lemma_es = e.get('lemma')  # Palabra en espaÃ±ol
        gloss_bora = e.get('gloss_bora', '')  # TraducciÃ³n(es) al Bora
        
        if not lemma_es or not gloss_bora:
            continue
        
        # Split por ";" para manejar mÃºltiples traducciones
        translations = [t.strip() for t in gloss_bora.split(';') if t.strip()]
        
        for translation in translations:
            key = (lemma_es, translation, 'salida_es_bora_final.json')
            if key in seen:
                continue
            seen.add(key)
            
            out.append({
                'lemma': lemma_es,              # Palabra en espaÃ±ol
                'gloss_bora': translation,       # UNA traducciÃ³n al Bora
                'gloss_es': None,                # NULL para ESâ†’Bora
                'direction': 'es_bora',          # Marcador de direcciÃ³n
                'pos': e.get('pos'),
                'pos_full': e.get('pos_full'),
                'variants': e.get('variants'),
                'synonyms': e.get('synonyms'),
                'source': 'salida_es_bora_final.json',
            })
    
    return out


def build_bora_docs_texts_es_bora(
    kind: str,
    items: List[Dict],
    lemma_meta: Dict[int, Dict],
) -> Tuple[List[str], List[Dict]]:
    """
    Genera textos para vectorizaciÃ³n (ESâ†’Bora)
    """
    texts = []
    records = []
    
    if kind == 'lemma':
        for it in items:
            lemma_id = it['id']
            meta = lemma_meta[lemma_id]
            
            # Formato: [LEMMA_ES] palabra_espaÃ±ol | DEF_BORA: traducciÃ³n_bora | POS: categorÃ­a
            content = f"[LEMMA_ES] {meta['lemma']} | DEF_BORA: {meta['gloss_bora']} | POS: {meta.get('pos_full') or meta.get('pos')}"
            
            texts.append(content)
            records.append({
                'kind': 'lemma',
                'parent_lemma_id': lemma_id,
                'content': content,
                'metadata': {
                    'source': 'salida_es_bora_final.json',
                    'direction': 'es_bora',
                    'lemma': meta['lemma'],
                    'gloss_bora': meta['gloss_bora'],
                    'pos': meta.get('pos'),
                    'pos_full': meta.get('pos_full'),
                }
            })
    
    elif kind == 'example':
        # MISMO formato que Boraâ†’ES (bidireccional)
        for it in items:
            meta = lemma_meta[it['lemma_id']]
            content = f"BORA: {it['bora_text']} [SEP] ES: {it['spanish_text']} [SEP] LEMMA: {meta['lemma']} POS: {meta.get('pos_full')}"
            
            texts.append(content)
            records.append({
                'kind': 'example',
                'parent_lemma_id': it['lemma_id'],
                'example_id': it['id'],
                'content': content,
                'metadata': {
                    'source': 'salida_es_bora_final.json',
                    'direction': 'es_bora',
                    'bora_text': it['bora_text'],
                    'spanish_text': it['spanish_text'],
                }
            })
    
    return texts, records
```

#### 3. **Procesamiento en Batches**
```python
# Mismo enfoque que salida.json
python backend/scripts/ingest_es_bora_docs.py \
  --path ../salida_es_bora_final.json \
  --batch-size 400 \          # Insert en batches de 400
  --embed-batch-size 64 \     # OpenAI embeddings: 64 por llamada
  --reset                      # Limpia ESâ†’Bora previos
```

---

## ðŸ“‹ InformaciÃ³n a Almacenar

### âœ… **Datos a Incluir**

1. **Lemmas ESâ†’Bora**:
   - Palabra en espaÃ±ol (`lemma`)
   - **CADA traducciÃ³n al Bora** (`gloss_bora`) - split por ";"
   - CategorÃ­a gramatical (`pos`, `pos_full`)
   - Variantes (si existen)
   - SinÃ³nimos (campo presente en JSON)

2. **Subentries**:
   - Frases compuestas en espaÃ±ol (`lemma` de subentry)
   - TraducciÃ³n(es) al Bora (`gloss_bora`)
   - CategorÃ­a gramatical

3. **Examples**:
   - Par completo Bora-EspaÃ±ol (igual que Boraâ†’ES)
   - RelaciÃ³n con lemma padre
   - CategorÃ­a contextual

4. **Embeddings**:
   - Vector 1536 dims para cada documento
   - Metadata completa (direcciÃ³n, source, etc.)

### âŒ **Datos a Omitir**

1. **SinÃ³nimos vacÃ­os** (`synonyms: []`)
2. **Variantes vacÃ­as** (`variants: []`)
3. **Duplicados** (misma palabra ES + traducciÃ³n Bora)
4. **Examples incompletos** (falta `bora` o `es`)

---

## ðŸŽ¯ Ventajas de Este Enfoque

### 1. **BÃºsqueda Bidireccional Nativa**
```python
# Usuario pregunta en espaÃ±ol:
query = "como se dice casa en bora"
# Encuentra documentos de AMBOS diccionarios:
# - [LEMMA] kÃ¡tyi | DEF_ES: casa (Boraâ†’ES)
# - [LEMMA_ES] casa | DEF_BORA: kÃ¡tyi (ESâ†’Bora)
```

### 2. **Redundancia Positiva**
- Ejemplos duplicados refuerzan bÃºsqueda semÃ¡ntica
- Mayor cobertura de variantes lingÃ¼Ã­sticas

### 3. **Filtrado Flexible**
```sql
-- Solo Boraâ†’ES:
SELECT * FROM bora_docs 
WHERE metadata->>'direction' = 'bora_es';

-- Solo ESâ†’Bora:
SELECT * FROM bora_docs 
WHERE metadata->>'direction' = 'es_bora';

-- Ambas direcciones (default):
SELECT * FROM bora_docs;
```

---

## ðŸ“Š PrÃ³ximos Pasos

### 1. **AnÃ¡lisis Exploratorio** âœ…
- [x] Comparar estructuras JSON
- [ ] Contar entradas Ãºnicas en `salida_es_bora_final.json`
- [ ] Validar calidad de datos (campos faltantes, duplicados)

### 2. **MigraciÃ³n de Schema** ðŸ”„
- [ ] Escribir SQL para agregar columnas `direction` y `gloss_bora`
- [ ] Aplicar migraciones en Supabase
- [ ] Validar constraints

### 3. **Script de Ingesta** ðŸ”„
- [ ] Adaptar `ingest_bora_docs.py` â†’ `ingest_es_bora_docs.py`
- [ ] Implementar split de `gloss_bora` por ";"
- [ ] Ajustar formato de documentos (LEMMA_ES, etc.)

### 4. **EjecuciÃ³n** ðŸš€
- [ ] Dry-run con `--limit 100`
- [ ] Validar embeddings generados
- [ ] Ingesta completa (~25,000 documentos)

### 5. **ValidaciÃ³n** âœ…
- [ ] Queries de prueba ESâ†’Bora
- [ ] Comparar resultados con/sin ESâ†’Bora
- [ ] Ajustar prompts si es necesario

---

## ðŸ’¡ Consideraciones Finales

### Costos OpenAI
```
~25,000 embeddings Ã— $0.00002/embedding = ~$0.50 USD
Total con Boraâ†’ES: ~$1.00-1.50 USD
```

### Tiempo de EjecuciÃ³n
```
~25,000 embeddings Ã· 64/batch = ~391 batches
~391 batches Ã— 2s/batch = ~13 minutos
```

### Storage Supabase
```
~30,000 documentos Ã— 1536 dims Ã— 4 bytes = ~184 MB de vectores
Total con Boraâ†’ES: ~250 MB
```

---

## ðŸ”— Referencias

- **Script base**: `backend/scripts/ingest_bora_docs.py`
- **Schema actual**: `docs/SETUP_SUPABASE.md`
- **JSON Boraâ†’ES**: `salida.json`
- **JSON ESâ†’Bora**: `salida_es_bora_final.json`
- **Embeddings**: OpenAI text-embedding-3-small (1536 dims)
