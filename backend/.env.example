# Archivo de ejemplo para variables de entorno
# Copiar este archivo como .env y completar con tus credenciales

# ==============================================
# CONFIGURACIÓN GENERAL
# ==============================================
APP_NAME=MIAPPBORA
APP_VERSION=1.0.0
DEBUG=True

# ==============================================
# SUPABASE CONFIGURATION
# ==============================================
# Instrucciones:
# 1. Crear cuenta en https://supabase.com
# 2. Crear nuevo proyecto llamado "miappbora"
# 3. Ir a Settings → API
# 4. Copiar los siguientes valores:

SUPABASE_URL=https://asdasdasd.supabase.co
SUPABASE_ANON_KEY=asdasdasdasdasdasasd.asdasdasdasdasdasdasdasdasd.asdasdasdasdasd
SUPABASE_SERVICE_KEY=asdasdas.asdasdasd.asdasdasdas-aaasdasd
# PostgreSQL Connection String (desde Supabase Settings → Database)
POSTGRES_URL="postgresql://postgres.asdasdasd:asd?S&asd@aws-1-sa-asdasd-1.pooler.supabase.com:5432/postgres"
DATABASE_URL=${POSTGRES_URL}

# ==============================================
# HUGGINGFACE CONFIGURATION
# ==============================================
# Instrucciones:
# 1. Crear cuenta en https://huggingface.co
# 2. Ir a Settings → Access Tokens
# 3. Crear nuevo token con permisos de lectura
# 4. Copiar el token aquí:
HUGGINGFACE_API_KEY=asdasdasdasdasdasd
# Modo de embeddings (true=API, false=LOCAL)
# API: Sin descargas, usa Inference API de HuggingFace
# LOCAL: Descarga modelo (~80MB) y ejecuta localmente (RECOMENDADO)
USE_EMBEDDING_API=false
# Modelos a utilizar (puedes cambiarlos según necesidad)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2  # Alternativa más robusta
LLM_MODEL=microsoft/DialoGPT-medium
EMBEDDING_DIMENSION=384
# ==============================================
# JWT AUTHENTICATION
# ==============================================
# IMPORTANTE: Cambiar SECRET_KEY en producción
# Generar con: openssl rand -hex 32
SECRET_KEY=cambiar-esta-clave-secreta-en-produccion-usar-openssl-rand-hex-32
# JWT_SECRET=<opcional>
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=10080
# ==============================================
# RAG CONFIGURATION
# ==============================================
TOP_K_RESULTS=3
SIMILARITY_THRESHOLD=0.7
LLM_BACKEND=transformers
LLM_MODEL=Qwen/Qwen3-1.7B
LLM_DEVICE_MAP=auto
LLM_DTYPE=auto
LLM_MAX_NEW_TOKENS=256
LLM_TEMPERATURE=0.35
LLM_TOP_P=0.9
LLM_ENABLE_THINKING=false