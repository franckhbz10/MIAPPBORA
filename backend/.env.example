# Archivo de ejemplo para variables de entorno
# Copiar este archivo como .env y completar con tus credenciales

# ==============================================
# CONFIGURACIÓN GENERAL
# ==============================================
APP_NAME=MIAPPBORA
APP_VERSION=1.0.0
DEBUG=True

# ==============================================
# SUPABASE CONFIGURATION
# ==============================================
# Instrucciones:
# 1. Crear cuenta en https://supabase.com
# 2. Crear nuevo proyecto llamado "miappbora"
# 3. Ir a Settings → API
# 4. Copiar los siguientes valores:

SUPABASE_URL=https://asdasdasd.supabase.co
SUPABASE_ANON_KEY=asdasdasdasdasdasasd.asdasdasdasdasdasdasdasdasd.asdasdasdasdasd
SUPABASE_SERVICE_KEY=asdasdas.asdasdasd.asdasdasdas-aaasdasd
# PostgreSQL Connection String (desde Supabase Settings → Database)
POSTGRES_URL="postgresql://postgres.asdasdasd:asd?S&asd@aws-1-sa-asdasd-1.pooler.supabase.com:5432/postgres"
DATABASE_URL=${POSTGRES_URL}

# ==============================================
# HUGGINGFACE CONFIGURATION
# ==============================================
# Instrucciones:
# 1. Crear cuenta en https://huggingface.co
# 2. Ir a Settings → Access Tokens
# 3. Crear nuevo token con permisos de lectura
# 4. Copiar el token aquí:
HUGGINGFACE_API_KEY=asdasdasdasdasdasd
# Modo de embeddings (true=API, false=LOCAL)
# API: Sin descargas, usa Inference API de HuggingFace
# LOCAL: Descarga modelo (~80MB) y ejecuta localmente (RECOMENDADO)
USE_EMBEDDING_API=false
# Modelos a utilizar (puedes cambiarlos según necesidad)
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2  # Alternativa más robusta
EMBEDDING_DIMENSION=384
# ==============================================
# JWT AUTHENTICATION
# ==============================================
# IMPORTANTE: Cambiar SECRET_KEY en producción
# Generar con: openssl rand -hex 32
SECRET_KEY=cambiar-esta-clave-secreta-en-produccion-usar-openssl-rand-hex-32
# JWT_SECRET=<opcional>
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=10080
# ==============================================
# RAG CONFIGURATION
# ==============================================
TOP_K_RESULTS=3
SIMILARITY_THRESHOLD=0.7

# ==============================================
# OPENAI API CONFIGURATION
# ==============================================
# Instrucciones:
# 1. Crear cuenta en https://platform.openai.com
# 2. Ir a API Keys → Create new secret key
# 3. Copiar tu API key aquí:
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# Habilitar/deshabilitar OpenAI (true=usa OpenAI, false=usa modelo local)
OPENAI_ENABLED=true
# Modelo a utilizar:
# - gpt-4o-mini: Más rápido y económico (~$0.15/1M tokens input, ~$0.60/1M tokens output)
# - gpt-4o: Más preciso pero más caro (~$2.50/1M tokens input, ~$10/1M tokens output)
# - gpt-3.5-turbo: Más económico (~$0.50/1M tokens input, ~$1.50/1M tokens output)
OPENAI_MODEL=gpt-4o-mini
# Temperatura (0.0 = más determinístico, 2.0 = más creativo)
OPENAI_TEMPERATURE=0.7
# Máximo de tokens en la respuesta
OPENAI_MAX_TOKENS=500
# Timeout para las peticiones (segundos)
OPENAI_TIMEOUT=30

# ==============================================
# FALLBACK: MODELO LOCAL (si OPENAI_ENABLED=false)
# ==============================================
LLM_BACKEND=transformers
LLM_MODEL=Qwen/Qwen3-1.7B
LLM_DEVICE_MAP=auto
LLM_DTYPE=auto
LLM_MAX_NEW_TOKENS=256
LLM_TEMPERATURE=0.35
LLM_TOP_P=0.9
LLM_ENABLE_THINKING=false