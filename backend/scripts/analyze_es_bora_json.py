"""
Script de an√°lisis exploratorio para salida_es_bora_final.json

Objetivo: Generar estad√≠sticas detalladas del diccionario ES‚ÜíBora
para dise√±ar estrategia de ingesta √≥ptima.

Uso:
    python backend/scripts/analyze_es_bora_json.py ../salida_es_bora_final.json
"""

import json
import sys
from pathlib import Path
from collections import Counter
from typing import Dict, List, Any

def analyze_json(file_path: Path) -> Dict[str, Any]:
    """Analiza estructura y contenido del JSON ES‚ÜíBora"""
    
    print(f"üìÑ Cargando {file_path}...")
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    print(f"‚úÖ JSON cargado: {len(data)} entradas\n")
    
    stats = {
        'total_entries': len(data),
        'unique_lemmas': set(),
        'pos_distribution': Counter(),
        'subentries_count': 0,
        'examples_count': 0,
        'gloss_bora_splits': Counter(),  # Cu√°ntas traducciones por lemma
        'empty_fields': {
            'variants': 0,
            'synonyms': 0,
            'gloss_bora': 0,
        },
        'subentries_with_examples': 0,
        'examples_missing_bora_or_es': 0,
    }
    
    for entry in data:
        # Lemmas √∫nicos
        lemma = entry.get('lemma')
        if lemma:
            stats['unique_lemmas'].add(lemma)
        
        # POS distribution
        pos_full = entry.get('pos_full', 'unknown')
        stats['pos_distribution'][pos_full] += 1
        
        # gloss_bora analysis (m√∫ltiples traducciones)
        gloss_bora = entry.get('gloss_bora', '')
        if not gloss_bora:
            stats['empty_fields']['gloss_bora'] += 1
        else:
            # Contar cu√°ntas traducciones (split por ";")
            translations = [t.strip() for t in gloss_bora.split(';') if t.strip()]
            stats['gloss_bora_splits'][len(translations)] += 1
        
        # Variants & Synonyms
        if not entry.get('variants'):
            stats['empty_fields']['variants'] += 1
        if not entry.get('synonyms'):
            stats['empty_fields']['synonyms'] += 1
        
        # Subentries
        subentries = entry.get('subentries', [])
        stats['subentries_count'] += len(subentries)
        
        for sub in subentries:
            # Examples en subentries
            sub_examples = sub.get('examples', [])
            if sub_examples:
                stats['subentries_with_examples'] += 1
            
            for ex in sub_examples:
                stats['examples_count'] += 1
                # Validar que tengan ambos campos
                if not ex.get('bora') or not ex.get('es'):
                    stats['examples_missing_bora_or_es'] += 1
        
        # Examples al nivel de entry principal
        main_examples = entry.get('examples', [])
        for ex in main_examples:
            stats['examples_count'] += 1
            if not ex.get('bora') or not ex.get('es'):
                stats['examples_missing_bora_or_es'] += 1
    
    stats['unique_lemmas'] = len(stats['unique_lemmas'])
    return stats


def print_report(stats: Dict[str, Any]):
    """Imprime reporte detallado de estad√≠sticas"""
    
    print("=" * 80)
    print("üìä AN√ÅLISIS DE salida_es_bora_final.json (Diccionario ES‚ÜíBora)")
    print("=" * 80)
    print()
    
    print("üìå RESUMEN GENERAL")
    print(f"  Total de entradas:       {stats['total_entries']:,}")
    print(f"  Lemmas √∫nicos (espa√±ol): {stats['unique_lemmas']:,}")
    print(f"  Subentradas:             {stats['subentries_count']:,}")
    print(f"  Ejemplos totales:        {stats['examples_count']:,}")
    print()
    
    print("üî§ DISTRIBUCI√ìN POR CATEGOR√çA GRAMATICAL (Top 10)")
    for pos, count in stats['pos_distribution'].most_common(10):
        pct = (count / stats['total_entries']) * 100
        print(f"  {pos:30s} {count:6,} ({pct:5.1f}%)")
    print()
    
    print("üîÄ M√öLTIPLES TRADUCCIONES EN gloss_bora")
    print("  (Distribuci√≥n de cu√°ntas traducciones tiene cada lemma)")
    for num_translations in sorted(stats['gloss_bora_splits'].keys()):
        count = stats['gloss_bora_splits'][num_translations]
        pct = (count / stats['total_entries']) * 100
        print(f"  {num_translations} traducci√≥n(es): {count:6,} lemmas ({pct:5.1f}%)")
    
    # Calcular documentos estimados por split
    total_docs_from_splits = sum(
        num * count for num, count in stats['gloss_bora_splits'].items()
    )
    print(f"\n  üìä Estimado de documentos LEMMA tras split: ~{total_docs_from_splits:,}")
    print()
    
    print("‚ö†Ô∏è CAMPOS VAC√çOS")
    print(f"  gloss_bora vac√≠o:  {stats['empty_fields']['gloss_bora']:,}")
    print(f"  variants vac√≠o:    {stats['empty_fields']['variants']:,}")
    print(f"  synonyms vac√≠o:    {stats['empty_fields']['synonyms']:,}")
    print()
    
    print("üìù EJEMPLOS")
    print(f"  Total de ejemplos:                 {stats['examples_count']:,}")
    print(f"  Subentradas con ejemplos:          {stats['subentries_with_examples']:,}")
    print(f"  Ejemplos incompletos (falta campo): {stats['examples_missing_bora_or_es']:,}")
    print()
    
    print("üéØ ESTIMACI√ìN DE DOCUMENTOS VECTORIZADOS")
    docs_lemma = total_docs_from_splits
    docs_subentry = stats['subentries_count']
    docs_example = stats['examples_count'] - stats['examples_missing_bora_or_es']
    total_docs = docs_lemma + docs_subentry + docs_example
    
    print(f"  LEMMA (tras split):      ~{docs_lemma:,}")
    print(f"  SUBENTRY:                ~{docs_subentry:,}")
    print(f"  EXAMPLE (v√°lidos):       ~{docs_example:,}")
    print(f"  {'‚îÄ' * 40}")
    print(f"  TOTAL ESTIMADO:          ~{total_docs:,}")
    print()
    
    print("üí∞ COSTOS ESTIMADOS (OpenAI text-embedding-3-small)")
    cost_per_1k = 0.00002 * 1000  # $0.02 per 1M tokens, ~1 token/embedding
    total_cost = (total_docs / 1000) * cost_per_1k
    print(f"  Embeddings a generar: ~{total_docs:,}")
    print(f"  Costo estimado:       ${total_cost:.2f} USD")
    print()
    
    print("‚è±Ô∏è TIEMPO ESTIMADO")
    batches = total_docs / 64  # OpenAI batch size
    time_minutes = (batches * 2) / 60  # ~2s por batch
    print(f"  Batches (64/batch):   ~{int(batches):,}")
    print(f"  Tiempo estimado:      ~{int(time_minutes)} minutos")
    print()
    
    print("=" * 80)
    print("‚úÖ An√°lisis completado")
    print("=" * 80)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Uso: python analyze_es_bora_json.py <ruta_al_json>")
        print("Ejemplo: python analyze_es_bora_json.py ../salida_es_bora_final.json")
        sys.exit(1)
    
    json_path = Path(sys.argv[1])
    
    if not json_path.exists():
        print(f"‚ùå Error: Archivo no encontrado: {json_path}")
        sys.exit(1)
    
    stats = analyze_json(json_path)
    print_report(stats)
